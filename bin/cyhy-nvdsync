#!/usr/bin/env python

"""Parse NVD CVE JSON feed and upsert a mongo collection.

Usage:
  cyhy-nvdsync [--section SECTION] --use-network
  cyhy-nvdsync [--section SECTION] [--gzipped] <file> ...
  cyhy-nvdsync (-h | --help)
  cyhy-nvdsync --version

Options:
  -g --gzipped                   Input file is gzipped.
  -h --help                      Show this screen.
  -n --use-network               Fetch NVD using the network.
  --version                      Show version.
  -s SECTION --section=SECTION   Configuration section to use.

"""

# standard python libraries
import gzip
import json
import logging
import urllib
from StringIO import StringIO

# third-party libraries (install with pip)
from docopt import docopt

# intra-project modules
from cyhy.db import database
from cyhy.util import util

NVD_URL = "https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-{year}.json.gz"
NVD_FIRST_YEAR = 2002


def parse_json(db, json_stream):
    data = json.load(json_stream)

    if data.get("CVE_data_type") != "CVE":
        raise ValueError("JSON does not look like valid NVD CVE data.")

    for entry in data.get("CVE_Items", []):
        cve_id = entry["cve"]["CVE_data_meta"]["ID"]
        if ("baseMetricV2" or "baseMetricV3") not in entry["impact"]:
            # Reject CVEs that don't have baseMetricV2 or baseMetricV3 CVSS data
            # Make sure they are removed from our db.
            db.CVEDoc.collection.remove({"_id": cve_id}, safe=False)
            print "x",
        else:
            print ".",
            version = "V3" if "baseMetricV3" in entry["impact"] else "V2"
            cvss_base_score = entry["impact"]["baseMetric" + version]["cvss" + version]["baseScore"]
            cvss_version = entry["impact"]["baseMetric" + version]["cvss" + version]["version"]
            entry_doc = db.CVEDoc({
                "_id": cve_id,
                "cvss_score": float(cvss_base_score),
                "cvss_version": cvss_version
            })
            entry_doc.save(safe=False)
    print "\n\n"


def process_file(db, filename, gzipped=False):
    if gzipped:
        stream = gzip.GzipFile(filename)
    else:
        stream = open(filename, "rb")
    parse_json(db, stream)


def process_url(db, url):
    socket = urllib.urlopen(url)
    buf = StringIO(socket.read())
    f = gzip.GzipFile(fileobj=buf)
    parse_json(db, f)


def generate_urls():
    current_year = util.utcnow().year
    years = range(NVD_FIRST_YEAR, current_year + 1)
    return [NVD_URL.format(**{"year": year}) for year in years]


def main():
    # Since docopt can generate SystemExit and DocoptExit exceptions
    # in certain normal use cases, we exclude it from our try clause.
    args = docopt(__doc__, version="v0.0.1")
    try:
        db = database.db_from_config(args["--section"])

        if args["--use-network"]:
            urls = generate_urls()
            for url in urls:
                print "-" * 10, url, "-" * 10
                process_url(db, url)
        else:
            for filename in args["<file>"]:
                print "-" * 10, filename, "-" * 10
                process_file(db, filename, gzipped=args["--gzipped"])
    except:
        logging.exception("Unexpected exception")


if __name__ == "__main__":
    main()
